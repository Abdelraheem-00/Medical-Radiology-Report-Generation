{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "22eaa759-833f-4c26-8e54-618e703fec5a",
    "_uuid": "e3aa8736-4273-4f48-8511-f946f230964a",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "86ee6c06-7793-4d93-8aca-5cf03a9397fd",
    "_uuid": "f18cd427-8964-4c18-9903-fd4250c19f1d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:06:58.869369Z",
     "iopub.status.busy": "2025-08-13T15:06:58.869073Z",
     "iopub.status.idle": "2025-08-13T15:06:59.945265Z",
     "shell.execute_reply": "2025-08-13T15:06:59.944535Z",
     "shell.execute_reply.started": "2025-08-13T15:06:58.869338Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ca8ddd5f-b764-47e7-8c54-6cbd89aaa0e0",
    "_uuid": "892b830e-f618-4285-8a42-74021e55e697",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:06:59.946755Z",
     "iopub.status.busy": "2025-08-13T15:06:59.946472Z",
     "iopub.status.idle": "2025-08-13T15:08:23.216726Z",
     "shell.execute_reply": "2025-08-13T15:08:23.215886Z",
     "shell.execute_reply.started": "2025-08-13T15:06:59.946738Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "31cc5fe8-1880-4c4f-ae8c-1d3d98a84dd9",
    "_uuid": "43bd5f73-ed94-403e-b735-fe08df518eaf",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2ae27ca4-9992-4693-9d9e-3f4e7a619c38",
    "_uuid": "ef5ee3c3-e73e-489f-8173-ea8d4ebe0335",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## reports file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2756205a-6874-4c95-b5c3-2f2097d4af38",
    "_uuid": "2ede7a5b-31b1-4167-b9d8-b1773addb4ee",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:23.217801Z",
     "iopub.status.busy": "2025-08-13T15:08:23.217594Z",
     "iopub.status.idle": "2025-08-13T15:08:23.311052Z",
     "shell.execute_reply": "2025-08-13T15:08:23.310302Z",
     "shell.execute_reply.started": "2025-08-13T15:08:23.21778Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/chest-xrays-indiana-university/indiana_reports.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7978c4b9-539e-47bd-afa3-6c56f3bfbc7f",
    "_uuid": "e16c2610-6cdf-4fb2-950c-e441c95177fe",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:23.312319Z",
     "iopub.status.busy": "2025-08-13T15:08:23.312008Z",
     "iopub.status.idle": "2025-08-13T15:08:23.350217Z",
     "shell.execute_reply": "2025-08-13T15:08:23.349437Z",
     "shell.execute_reply.started": "2025-08-13T15:08:23.312294Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3358b80c-0e50-4b17-815a-5c78c9a68384",
    "_uuid": "8c3a8f3e-423e-4ebb-be1b-6e26a4188bdb",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    " ### some insights\n",
    "\n",
    "- **uid:** *identifier to match with image metadata*.\n",
    "\n",
    "- **MeSH:** *Medical Subject Headingsâ€”terms or tags related to the study*.\n",
    "\n",
    "- **Problems:** *Additional annotated issues (if any).*\n",
    "\n",
    "- **image:** *image descriptive field*\n",
    "\n",
    "- **indication:** *Reason or clinical indication for the X-ray.*\n",
    "\n",
    "- **comparison:** *Reference to prior studies for comparison, not available for patient privacy.*\n",
    "\n",
    "- **Findings:** *Observations by the radiologist based on image analysis.*\n",
    "\n",
    "- **impression:** *The final diagnostic impression or conclusion.*\n",
    "\n",
    "- THE **XXXX** signifies confidential information that was removed from the reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fe30d7b7-0370-4216-9092-55d67ceecb69",
    "_uuid": "499302af-fd65-40a9-bee7-0a91bb3caed8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:23.352374Z",
     "iopub.status.busy": "2025-08-13T15:08:23.352169Z",
     "iopub.status.idle": "2025-08-13T15:08:23.360542Z",
     "shell.execute_reply": "2025-08-13T15:08:23.359752Z",
     "shell.execute_reply.started": "2025-08-13T15:08:23.352358Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "57b8b9ca-6133-4a59-956e-4f5f2cddecd8",
    "_uuid": "e705bfc9-7795-4f9a-a60e-5de268560aab",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:23.361595Z",
     "iopub.status.busy": "2025-08-13T15:08:23.36134Z",
     "iopub.status.idle": "2025-08-13T15:08:23.382883Z",
     "shell.execute_reply": "2025-08-13T15:08:23.382307Z",
     "shell.execute_reply.started": "2025-08-13T15:08:23.361569Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.dropna(subset={'findings','impression'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "83c81a47-47c5-4ae3-b3c0-bd72e552091b",
    "_uuid": "2b20d370-e49d-4dab-9ab5-37ea596a79b5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:23.383995Z",
     "iopub.status.busy": "2025-08-13T15:08:23.383676Z",
     "iopub.status.idle": "2025-08-13T15:08:23.405746Z",
     "shell.execute_reply": "2025-08-13T15:08:23.405165Z",
     "shell.execute_reply.started": "2025-08-13T15:08:23.383966Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "cd01359b-590d-453b-9e6a-289e6a30a1de",
    "_uuid": "ac2e9636-751e-4bf4-b25e-fa9dbe4e9b0f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:23.406753Z",
     "iopub.status.busy": "2025-08-13T15:08:23.406464Z",
     "iopub.status.idle": "2025-08-13T15:08:23.426108Z",
     "shell.execute_reply": "2025-08-13T15:08:23.4256Z",
     "shell.execute_reply.started": "2025-08-13T15:08:23.406733Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# getting report from findings and impression\n",
    "df['report']=df['findings']+' '+df['impression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e8ade2d3-1aad-4e84-99b5-d4969550595f",
    "_uuid": "47fb05f0-a14c-4629-adcf-fd6c6ff9ef23",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:23.427046Z",
     "iopub.status.busy": "2025-08-13T15:08:23.426823Z",
     "iopub.status.idle": "2025-08-13T15:08:23.445139Z",
     "shell.execute_reply": "2025-08-13T15:08:23.444398Z",
     "shell.execute_reply.started": "2025-08-13T15:08:23.427022Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['report']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2fff7515-f011-4619-80c2-7290ad03cc8c",
    "_uuid": "4193b022-f934-45d3-b9a6-55bc1e034916",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## projection file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3fdd7f49-4881-4b0f-a349-1668eab47483",
    "_uuid": "9427335b-db23-4b0b-a393-f08d7f884a15",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:23.446195Z",
     "iopub.status.busy": "2025-08-13T15:08:23.445939Z",
     "iopub.status.idle": "2025-08-13T15:08:23.484888Z",
     "shell.execute_reply": "2025-08-13T15:08:23.484226Z",
     "shell.execute_reply.started": "2025-08-13T15:08:23.446169Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "proj_df=pd.read_csv(\"/kaggle/input/chest-xrays-indiana-university/indiana_projections.csv\")\n",
    "proj_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c807a502-2213-43ac-83d5-ee5c431d6f0f",
    "_uuid": "aace6c24-d32c-4aff-a778-99fa53b5ea8a",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "### Projection file insights\n",
    "- **uid:** Unique identifier linking to a particular study or patient.\n",
    "\n",
    "- **filename:** The image fileâ€™s name.\n",
    "\n",
    "- **projection:** The view orientation,frontal or \"lateral."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e6202b1d-ace6-4f01-b336-0200adc13c91",
    "_uuid": "63f04266-d1d8-4f75-95f1-e7dfd04c29f7",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    " ## Visualization Image Captions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d00b4bfe-cf35-4f9b-abba-a9e599388d39",
    "_uuid": "22455998-9ce0-41e6-bbe3-95d57ab69142",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "IT appears that each patient has 2 chest x-ray images frontal and lateral. every two rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e7d4c702-71da-485d-b961-465bed5f17ea",
    "_uuid": "08e5b3bc-9353-41a0-a608-53d9c7c8d709",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "07da469c-2360-44e4-8b3e-480fb747a214",
    "_uuid": "da0794a8-3dcd-4640-ab80-a7f277e0ea0d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Data cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f90a18e1-d7f7-45d1-bccb-148725f46240",
    "_uuid": "09bb42e9-ff2c-4251-b7f1-3abbaab9373b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:23.48621Z",
     "iopub.status.busy": "2025-08-13T15:08:23.485621Z",
     "iopub.status.idle": "2025-08-13T15:08:23.49006Z",
     "shell.execute_reply": "2025-08-13T15:08:23.489394Z",
     "shell.execute_reply.started": "2025-08-13T15:08:23.486191Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def cleaning(s):\n",
    "    s=s.lower()               # lowercasing\n",
    "    s = re.sub(r\"[^a-z.,]\", \" \", s)  # Replaces any character that is NOT a lowercase letter , period or a comma with space\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip() # remove multiple spaces with single space\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a88eba6d-9673-4c93-b5dd-b560c10b09e8",
    "_uuid": "c787ec06-6639-49e0-9a64-98d3f9448599",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:23.491157Z",
     "iopub.status.busy": "2025-08-13T15:08:23.490892Z",
     "iopub.status.idle": "2025-08-13T15:08:23.507435Z",
     "shell.execute_reply": "2025-08-13T15:08:23.506848Z",
     "shell.execute_reply.started": "2025-08-13T15:08:23.491136Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.report.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2093e332-65c5-4165-baeb-203cca6f9130",
    "_uuid": "2227bd8e-98fa-406a-83f6-fd49dbd1e89f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:23.508513Z",
     "iopub.status.busy": "2025-08-13T15:08:23.508249Z",
     "iopub.status.idle": "2025-08-13T15:08:23.610442Z",
     "shell.execute_reply": "2025-08-13T15:08:23.609889Z",
     "shell.execute_reply.started": "2025-08-13T15:08:23.508475Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.report=df.report.apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3cb625b5-e667-42a2-914e-d829f3960dfb",
    "_uuid": "06848f4f-02ba-45c9-8f9d-17137d621384",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:23.613588Z",
     "iopub.status.busy": "2025-08-13T15:08:23.613374Z",
     "iopub.status.idle": "2025-08-13T15:08:23.618018Z",
     "shell.execute_reply": "2025-08-13T15:08:23.617528Z",
     "shell.execute_reply.started": "2025-08-13T15:08:23.613573Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df.report.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "be976b3c-ad06-49a5-80b5-58585d026cd1",
    "_uuid": "9f42537b-71ca-4e90-957e-5876a80d7468",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Merging the files into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b297ec57-40cd-44b8-8054-0abb3efb4633",
    "_uuid": "e564cc96-a05f-4091-afa0-421f60e111c7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:23.618907Z",
     "iopub.status.busy": "2025-08-13T15:08:23.618675Z",
     "iopub.status.idle": "2025-08-13T15:08:23.651423Z",
     "shell.execute_reply": "2025-08-13T15:08:23.650832Z",
     "shell.execute_reply.started": "2025-08-13T15:08:23.61889Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df=pd.merge(df,proj_df,how='inner',on='uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3c96ad41-c940-43f6-b3b1-927120726a9d",
    "_uuid": "3d2fc180-dfe0-4995-a328-a9f2dbd61986",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:23.65235Z",
     "iopub.status.busy": "2025-08-13T15:08:23.652079Z",
     "iopub.status.idle": "2025-08-13T15:08:23.66543Z",
     "shell.execute_reply": "2025-08-13T15:08:23.66477Z",
     "shell.execute_reply.started": "2025-08-13T15:08:23.652333Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6078ef70-86f1-46da-a574-6da9dec2dbc3",
    "_uuid": "c79a0b06-a192-455f-afa1-3265fa8e53a7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:23.666415Z",
     "iopub.status.busy": "2025-08-13T15:08:23.666154Z",
     "iopub.status.idle": "2025-08-13T15:08:23.689309Z",
     "shell.execute_reply": "2025-08-13T15:08:23.688679Z",
     "shell.execute_reply.started": "2025-08-13T15:08:23.666397Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df['path']=\"/kaggle/input/chest-xrays-indiana-university/images/images_normalized/\"+df['filename']\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1c440f42-5c76-4fdd-9852-f04dda78253d",
    "_uuid": "e1c414dc-3abf-4524-b9e2-ca5cd0c045a7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:23.690214Z",
     "iopub.status.busy": "2025-08-13T15:08:23.689983Z",
     "iopub.status.idle": "2025-08-13T15:08:23.705783Z",
     "shell.execute_reply": "2025-08-13T15:08:23.70526Z",
     "shell.execute_reply.started": "2025-08-13T15:08:23.690197Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "image_folder = \"/kaggle/input/chest-xrays-indiana-university/images/images_normalized\"  # change to your dataset path\n",
    "\n",
    "def show_image_with_caption(row):\n",
    "    img_path = os.path.join(image_folder, row['filename'])\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(row['report'], fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b113feba-1288-410e-aa69-e569036b4285",
    "_uuid": "345193c2-1793-4b29-b6e9-d46fd1047d59",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:23.706781Z",
     "iopub.status.busy": "2025-08-13T15:08:23.706552Z",
     "iopub.status.idle": "2025-08-13T15:08:26.710835Z",
     "shell.execute_reply": "2025-08-13T15:08:26.709895Z",
     "shell.execute_reply.started": "2025-08-13T15:08:23.706766Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for _, row in df.head(5).iterrows():\n",
    "    show_image_with_caption(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cb8413b9-6565-464f-8d26-fd868bd7fd79",
    "_uuid": "1ab2dd86-e50a-4850-acb2-78eacb9ee6bc",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c40ed159-b77c-4560-bc43-095338c0eb0e",
    "_uuid": "2617e32d-bd6e-4602-b298-c1ee03d46f55",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:26.712191Z",
     "iopub.status.busy": "2025-08-13T15:08:26.711819Z",
     "iopub.status.idle": "2025-08-13T15:08:30.745996Z",
     "shell.execute_reply": "2025-08-13T15:08:30.745164Z",
     "shell.execute_reply.started": "2025-08-13T15:08:26.712165Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from collections import Counter\n",
    "text=\" \".join(df['report'])\n",
    "tokens=nltk.word_tokenize(text)\n",
    "counterr=Counter(tokens)\n",
    "print(tokens[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4c9c7d05-5ed4-43d0-8fa3-07857be05cda",
    "_uuid": "bfc483fe-6f03-438e-bc33-6d8c0020d32d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:30.747415Z",
     "iopub.status.busy": "2025-08-13T15:08:30.746847Z",
     "iopub.status.idle": "2025-08-13T15:08:30.751689Z",
     "shell.execute_reply": "2025-08-13T15:08:30.750914Z",
     "shell.execute_reply.started": "2025-08-13T15:08:30.747387Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "word2idx = {\"<PAD>\": 0, \"<UNK>\": 1, \"<SOS>\": 2, \"<EOS>\": 3}\n",
    "j = 4\n",
    "for i in counterr.keys():\n",
    "    word2idx[i]=j\n",
    "    j+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8196a24a-dcb6-454e-8390-00cd1037bc5e",
    "_uuid": "1b10cd35-3a96-4b1b-8a97-f6f97ce20565",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:30.753245Z",
     "iopub.status.busy": "2025-08-13T15:08:30.752912Z",
     "iopub.status.idle": "2025-08-13T15:08:33.837562Z",
     "shell.execute_reply": "2025-08-13T15:08:33.836798Z",
     "shell.execute_reply.started": "2025-08-13T15:08:30.753206Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from typing import List, Dict\n",
    "\n",
    "class Tokenizer:\n",
    "    \"\"\"\n",
    "    A custom tokenizer for mapping text <-> token IDs for NLP models.\n",
    "    \n",
    "    Attributes:\n",
    "        word2idx (dict): Maps words to unique integer IDs.\n",
    "        idx2word (dict): Maps IDs back to words.\n",
    "        pad_token, unk_token, sos_token, eos_token (str): Special token strings.\n",
    "        pad_id, unk_id, sos_id, eos_id (int): Special token IDs.\n",
    "        vocab_size (int): Number of unique tokens in the vocabulary.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, word2idx: Dict[str, int]):\n",
    "        \"\"\"\n",
    "        Initialize the tokenizer with a vocabulary mapping.\n",
    "        \n",
    "        Args:\n",
    "            word2idx: Dictionary mapping words to integer IDs.\n",
    "        \"\"\"\n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = {v: k for k, v in word2idx.items()}\n",
    "\n",
    "        # Special tokens\n",
    "        self.pad_token = \"<PAD>\"\n",
    "        self.unk_token = \"<UNK>\"\n",
    "        self.sos_token = \"<SOS>\"\n",
    "        self.eos_token = \"<EOS>\"\n",
    "\n",
    "        # Special token IDs\n",
    "        self.pad_id = self.word2idx[self.pad_token]\n",
    "        self.unk_id = self.word2idx[self.unk_token]\n",
    "        self.sos_id = self.word2idx[self.sos_token]\n",
    "        self.eos_id = self.word2idx[self.eos_token]\n",
    "\n",
    "        self.vocab_size = len(word2idx)\n",
    "\n",
    "    def encode(self, sentence: str, add_special_tokens: bool = True) -> List[int]:\n",
    "        \"\"\"\n",
    "        Convert a sentence into a list of token IDs.\n",
    "\n",
    "        Args:\n",
    "            sentence: The sentence to encode.\n",
    "            add_special_tokens: Whether to add <SOS> and <EOS> around the sequence.\n",
    "\n",
    "        Returns:\n",
    "            List of token IDs representing the sentence.\n",
    "        \"\"\"\n",
    "        # Tokenize and lowercase\n",
    "        tokens = nltk.word_tokenize(sentence.lower())\n",
    "\n",
    "        # Convert tokens to IDs, use <UNK> if token not in vocabulary\n",
    "        token_ids = [self.word2idx.get(token, self.unk_id) for token in tokens]\n",
    "\n",
    "        # Add start/end markers if required\n",
    "        if add_special_tokens:\n",
    "            token_ids = [self.sos_id] + token_ids + [self.eos_id]\n",
    "\n",
    "        return token_ids\n",
    "\n",
    "    def decode(self, token_ids: List[int], skip_special_tokens: bool = True) -> str:\n",
    "        \"\"\"\n",
    "        Convert a list of token IDs back into a sentence.\n",
    "\n",
    "        Args:\n",
    "            token_ids: List of integer IDs.\n",
    "            skip_special_tokens: If True, removes <PAD>, <SOS>, and <EOS> from output.\n",
    "\n",
    "        Returns:\n",
    "            Decoded sentence as a string.\n",
    "        \"\"\"\n",
    "        words = []\n",
    "        for idx in token_ids:\n",
    "            word = self.idx2word.get(idx, self.unk_token)\n",
    "            # Skip special tokens if requested\n",
    "            if skip_special_tokens and word in {self.pad_token, self.sos_token, self.eos_token}:\n",
    "                continue\n",
    "            words.append(word)\n",
    "\n",
    "        return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "540600c4-8f7b-4173-8457-041cbf010245",
    "_uuid": "164cfd92-f034-4a07-a22b-9ffbbbb1e3ef",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:33.838868Z",
     "iopub.status.busy": "2025-08-13T15:08:33.838566Z",
     "iopub.status.idle": "2025-08-13T15:08:33.859755Z",
     "shell.execute_reply": "2025-08-13T15:08:33.858977Z",
     "shell.execute_reply.started": "2025-08-13T15:08:33.838847Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Example usage:\n",
    "tokenizer = Tokenizer(word2idx)\n",
    "ids = tokenizer.encode(\"No pleural effusion.\")\n",
    "print(ids)  # Example: [2, 6, 300, 450, 3]\n",
    "print(tokenizer.decode(ids))  # \"no pleural effusion .\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f5235d69-c944-4b7e-bc08-4dc80163e67b",
    "_uuid": "b8192430-8595-4978-b99b-39b9c753000d",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "### Adding tokonized sequence in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1910de19-2003-46c0-a556-29b3a65a8ead",
    "_uuid": "6474f7d3-acd8-4dc4-b52a-2ca831064d34",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:33.860883Z",
     "iopub.status.busy": "2025-08-13T15:08:33.860637Z",
     "iopub.status.idle": "2025-08-13T15:08:36.82586Z",
     "shell.execute_reply": "2025-08-13T15:08:36.825003Z",
     "shell.execute_reply.started": "2025-08-13T15:08:33.860862Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df[\"sequence\"]=df[\"report\"].apply(tokenizer.encode)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1f37d35d-30c9-449d-b7cc-b3d13dd34be9",
    "_uuid": "eb6ac9f0-cae8-4437-b2d2-de546b152c16",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:36.827024Z",
     "iopub.status.busy": "2025-08-13T15:08:36.826801Z",
     "iopub.status.idle": "2025-08-13T15:08:36.832499Z",
     "shell.execute_reply": "2025-08-13T15:08:36.83184Z",
     "shell.execute_reply.started": "2025-08-13T15:08:36.827Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "row=df.iloc[0]\n",
    "tokenizer.decode(row.sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "348a7a2f-2796-41a1-bf42-6c5d9c0991b3",
    "_uuid": "14f78510-c279-45b4-936d-d1901b577187",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Padding and trimming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "68a5728b-4ad6-45ac-b9ef-8a2d9207b17b",
    "_uuid": "474c809f-4b24-4ce0-8985-da0cf4617a92",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:36.833867Z",
     "iopub.status.busy": "2025-08-13T15:08:36.833376Z",
     "iopub.status.idle": "2025-08-13T15:08:37.040461Z",
     "shell.execute_reply": "2025-08-13T15:08:37.039674Z",
     "shell.execute_reply.started": "2025-08-13T15:08:36.833847Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lengths=[len(i) for i in df['sequence']]\n",
    "sns.violinplot(lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5f434f4e-ca0a-4e1d-9008-dbbf8b3acf5a",
    "_uuid": "bfbd15f8-6869-4d24-aa41-b1de5ec3e5bf",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "Max length of sequence from the plot around 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1d0ae1e7-d6c0-4fa8-b9f9-66ef7b552846",
    "_uuid": "e785e354-494d-49b4-a008-781580612655",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:37.041491Z",
     "iopub.status.busy": "2025-08-13T15:08:37.041288Z",
     "iopub.status.idle": "2025-08-13T15:08:37.059885Z",
     "shell.execute_reply": "2025-08-13T15:08:37.059106Z",
     "shell.execute_reply.started": "2025-08-13T15:08:37.041475Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "seq_len=100\n",
    "def pad_and_trim(seq):\n",
    "    # Truncate if longer\n",
    "    if len(seq) > seq_len:\n",
    "        seq = seq[:seq_len-1] + [tokenizer.eos_id] \n",
    "        return seq\n",
    "    else:\n",
    "        return seq + [tokenizer.pad_id] * (seq_len - len(seq))\n",
    "df.sequence=df.sequence.apply(pad_and_trim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ae51fdfa-e42b-476a-bbe9-fc03ea4bae5b",
    "_uuid": "7055067c-6bff-4e62-9103-ea2b73950799",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9eef431a-687f-4b33-8269-c2bd19b00f24",
    "_uuid": "3a733acf-b315-4e88-b7b0-52cac9fd7a12",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a1bef52f-ed0f-4411-9167-f516c737f786",
    "_uuid": "4fe9282f-ede3-46d0-a152-ead6ceb75dca",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:37.060909Z",
     "iopub.status.busy": "2025-08-13T15:08:37.060677Z",
     "iopub.status.idle": "2025-08-13T15:08:37.083802Z",
     "shell.execute_reply": "2025-08-13T15:08:37.08313Z",
     "shell.execute_reply.started": "2025-08-13T15:08:37.060891Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df,temp=train_test_split(df,test_size=0.2)\n",
    "test_df,val_df=train_test_split(temp,test_size=0.5)\n",
    "print(len(train_df),len(test_df),len(val_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "024c1549-f5cd-4a35-a412-6eb69beb97c3",
    "_uuid": "14413679-d0dd-44ee-be92-b281905d35fc",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "46b92d9e-02d1-4e8c-a962-d76c721a896b",
    "_uuid": "359c62fa-2d4f-42cc-a29d-12f48c1f16b7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:37.084741Z",
     "iopub.status.busy": "2025-08-13T15:08:37.084494Z",
     "iopub.status.idle": "2025-08-13T15:08:46.014522Z",
     "shell.execute_reply": "2025-08-13T15:08:46.013779Z",
     "shell.execute_reply.started": "2025-08-13T15:08:37.084718Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "img_size=(512,512)\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "# Data Augmentation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(\n",
    "        brightness=0.2, \n",
    "        contrast=0.2, \n",
    "        saturation=0.2, \n",
    "        hue=0.02\n",
    "    ),\n",
    "    transforms.RandomResizedCrop(img_size, scale=(0.8, 1.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "class IUXrayDataset(Dataset):\n",
    "    def __init__(self, image_paths, captions_seq, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.captions_seq = captions_seq\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        caption_seq = self.captions_seq[idx]\n",
    "        return image, torch.tensor(caption_seq, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "05f06983-d527-4ea7-8a99-1f78033fc291",
    "_uuid": "53cb5be4-21a6-4642-bf2a-d3e184e3d620",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:46.016219Z",
     "iopub.status.busy": "2025-08-13T15:08:46.015439Z",
     "iopub.status.idle": "2025-08-13T15:08:46.024017Z",
     "shell.execute_reply": "2025-08-13T15:08:46.023253Z",
     "shell.execute_reply.started": "2025-08-13T15:08:46.016198Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = IUXrayDataset(\n",
    "    image_paths=list(train_df['path']),\n",
    "    captions_seq=list(train_df['sequence']),\n",
    "    transform=train_transforms\n",
    ")\n",
    "test_dataset = IUXrayDataset(\n",
    "    image_paths=list(test_df['path']),\n",
    "    captions_seq=list(test_df['sequence']),\n",
    "    transform=image_transforms\n",
    ")\n",
    "val_dataset = IUXrayDataset(\n",
    "    image_paths=list(val_df['path']),\n",
    "    captions_seq=list(val_df['sequence']),\n",
    "    transform=image_transforms\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    drop_last=True\n",
    ")\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "20d9ebf7-c7d6-4f54-a70e-be27e8335d02",
    "_uuid": "bf3c243c-dac6-4438-9d81-5adf51f4e8e3",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:46.025477Z",
     "iopub.status.busy": "2025-08-13T15:08:46.024855Z",
     "iopub.status.idle": "2025-08-13T15:08:46.051633Z",
     "shell.execute_reply": "2025-08-13T15:08:46.051048Z",
     "shell.execute_reply.started": "2025-08-13T15:08:46.025457Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    drop_last=True\n",
    ")\n",
    "print(len(test_loader))\n",
    "\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    drop_last=True\n",
    ")\n",
    "print(len(val_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6fcc4e68-5b58-4ca8-a40d-7994664e3685",
    "_uuid": "3ceda198-01c0-4fe4-b5b2-c08a706c9ef3",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Image Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "626c3168-b849-46f0-84ba-e0c52faff61f",
    "_uuid": "f703b7ee-e8f9-4fa9-bc58-b83ef4c6e6fd",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:46.05252Z",
     "iopub.status.busy": "2025-08-13T15:08:46.052269Z",
     "iopub.status.idle": "2025-08-13T15:08:46.078932Z",
     "shell.execute_reply": "2025-08-13T15:08:46.078095Z",
     "shell.execute_reply.started": "2025-08-13T15:08:46.052488Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self,embed_dim=512):\n",
    "        super(ImageEncoder,self).__init__()\n",
    "        effnet=models.efficientnet_b4(pretrained=True)\n",
    "\n",
    "        # remove classification head\n",
    "        self.backbone=effnet.features # Output shape: [B, 1792, H/32, W/32]\n",
    "\n",
    "        # Freeze backbone\n",
    "        for param in self.backbone.parameters():\n",
    "            param.requires_grad=False\n",
    "\n",
    "        # Adaptive flattening: [B, 1792,H/32, W/32] â†’ [B, 49, 1792]\n",
    "        self.pool = nn.AdaptiveAvgPool2d((7, 7))  # [B, 1792,H/32, W/32] â†’ [B, 1792, 7, 7]\n",
    "        self.flatten = nn.Flatten(2)  # dims (B, C, H, W) â†’ (B, C, H*W)\n",
    "        self.transpose = lambda x: x.permute(0, 2, 1)  # (B, C, L) â†’ (B, L, C)\n",
    "\n",
    "        self.project = nn.Linear(1792, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)               # (B, 1792, H, W)\n",
    "        x = self.pool(x)                   # (B, 1792, 7, 7)\n",
    "        x = self.flatten(x)                # (B, 1792, 49)\n",
    "        x = self.transpose(x)              # (B, 49, 1792)\n",
    "        x = self.project(x)                # (B, 49, embed_dim)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e96e71fd-b790-47b3-9089-4bb2c4d8eb40",
    "_uuid": "054e05ed-985e-492a-8387-e9e53ca50a7f",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "## Getting Image and Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e8cda1dc-2513-463a-946e-2a582cef4ee6",
    "_uuid": "894c140c-9f87-46f1-b471-5f4722067db4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:08:46.080483Z",
     "iopub.status.busy": "2025-08-13T15:08:46.080212Z",
     "iopub.status.idle": "2025-08-13T15:09:32.802958Z",
     "shell.execute_reply": "2025-08-13T15:09:32.802176Z",
     "shell.execute_reply.started": "2025-08-13T15:08:46.080458Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i in train_loader:\n",
    "    img_batch,seq_batch = i\n",
    "    break\n",
    "print(img_batch.shape)\n",
    "\n",
    "encoder = ImageEncoder(512)\n",
    "out = encoder(img_batch)\n",
    "print(out.shape)  # [batch_size, 49, 512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5f8dc465-323c-4478-83fd-b87c84f4a1af",
    "_uuid": "e120a335-a954-4c17-a126-18f5505197bc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:09:32.804367Z",
     "iopub.status.busy": "2025-08-13T15:09:32.804021Z",
     "iopub.status.idle": "2025-08-13T15:09:32.809107Z",
     "shell.execute_reply": "2025-08-13T15:09:32.80842Z",
     "shell.execute_reply.started": "2025-08-13T15:09:32.80433Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(seq_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8ddc485c-3d65-498d-a2cd-b8b00186778e",
    "_uuid": "ec48853d-b273-4990-a3e0-68ccee55d4a4",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:09:32.810027Z",
     "iopub.status.busy": "2025-08-13T15:09:32.809853Z",
     "iopub.status.idle": "2025-08-13T15:09:33.056708Z",
     "shell.execute_reply": "2025-08-13T15:09:33.056156Z",
     "shell.execute_reply.started": "2025-08-13T15:09:32.810014Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, max_len, embed_dim):\n",
    "        super(PositionalEmbedding, self).__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.position_embedding = nn.Embedding(max_len, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [B, T]\n",
    "        positions = torch.arange(0, x.size(1), device=x.device).unsqueeze(0)\n",
    "        pos_embed = self.position_embedding(positions)   # [1, T, D]\n",
    "        tok_embed = self.token_embedding(x)              # [B, T, D]\n",
    "        return tok_embed + pos_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4e331e63-94cf-45d1-b2a3-5c95f487e831",
    "_uuid": "9e2c8474-ad24-44c1-bf66-328666ae30a0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:09:33.057482Z",
     "iopub.status.busy": "2025-08-13T15:09:33.057295Z",
     "iopub.status.idle": "2025-08-13T15:09:33.092635Z",
     "shell.execute_reply": "2025-08-13T15:09:33.09207Z",
     "shell.execute_reply.started": "2025-08-13T15:09:33.057467Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "embed = PositionalEmbedding(vocab_size=tokenizer.vocab_size, max_len=102, embed_dim=512)\n",
    "x = torch.tensor([row.sequence,row.sequence], dtype=torch.long) # batch of 2\n",
    "output = embed(x)\n",
    "print(output.shape)  # [B, sequence_len, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "20fe83f2-9372-4d3f-8fd4-9042ffdd8a3a",
    "_uuid": "3511ebf1-6d88-4983-9bcd-b8e259113603",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:09:33.093616Z",
     "iopub.status.busy": "2025-08-13T15:09:33.093363Z",
     "iopub.status.idle": "2025-08-13T15:09:33.099258Z",
     "shell.execute_reply": "2025-08-13T15:09:33.098531Z",
     "shell.execute_reply.started": "2025-08-13T15:09:33.093593Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            embed_dim (int): The dimensionality of the input and output.\n",
    "            num_heads (int): The number of attention heads.\n",
    "            ff_dim (int): The dimensionality of the inner-layer in the feed-forward network.\n",
    "            dropout (float): The dropout probability.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, embed_dim)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the Transformer Encoder Block.\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape [B, N, D] (Batch, SequenceLength, EmbedDim)\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of the same shape [B, N, D]\n",
    "        \"\"\"\n",
    "        # Self-attention part\n",
    "        attn_output, _ = self.self_attn(x, x, x)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Feed-forward part\n",
    "        ff_output = self.ff(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7e0d0f38-8c48-43ae-8686-30277e7c3250",
    "_uuid": "73e0e1fc-9b08-4231-b9fa-e6477856b1a8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:09:33.100253Z",
     "iopub.status.busy": "2025-08-13T15:09:33.100004Z",
     "iopub.status.idle": "2025-08-13T15:09:33.120475Z",
     "shell.execute_reply": "2025-08-13T15:09:33.119787Z",
     "shell.execute_reply.started": "2025-08-13T15:09:33.100224Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TransformerDecoderBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.cross_attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, embed_dim)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.norm3 = nn.LayerNorm(embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_out, tgt_mask=None):\n",
    "        # Masked self-attention\n",
    "        _x = self.norm1(x + self.dropout(self.self_attn(x, x, x, attn_mask=tgt_mask)[0]))\n",
    "        # Cross-attention\n",
    "        _x = self.norm2(_x + self.dropout(self.cross_attn(_x, enc_out, enc_out)[0]))\n",
    "        # Feedforward\n",
    "        out = self.norm3(_x + self.dropout(self.ff(_x)))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fae9c2f0-ab2c-43e9-a5b0-846390b1c80b",
    "_uuid": "68853dd7-e8ba-4ee5-8827-954c91d8576d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:09:33.121433Z",
     "iopub.status.busy": "2025-08-13T15:09:33.12121Z",
     "iopub.status.idle": "2025-08-13T15:09:33.141766Z",
     "shell.execute_reply": "2025-08-13T15:09:33.141278Z",
     "shell.execute_reply.started": "2025-08-13T15:09:33.121409Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CaptionDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, ff_dim, num_heads, max_len, num_layers):\n",
    "        super().__init__()\n",
    "        self.pos_embed = PositionalEmbedding(vocab_size, max_len, embed_dim)\n",
    "        self.dec_layers = nn.ModuleList([\n",
    "            TransformerDecoderBlock(embed_dim, num_heads, ff_dim) \n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        self.output_proj = nn.Linear(embed_dim, vocab_size)\n",
    "\n",
    "    def make_causal_mask(self, size):\n",
    "        return torch.triu(torch.ones(size, size), diagonal=1).bool()\n",
    "\n",
    "    def forward(self, tgt, enc_out):\n",
    "        \"\"\"\n",
    "        tgt: [B, T]       -- tokenized caption (with <SOS>)\n",
    "        enc_out: [B, N, D] -- image features\n",
    "        \"\"\"\n",
    "        x = self.pos_embed(tgt)  # [B, T, D]\n",
    "\n",
    "        # Create causal mask for masked self-attn\n",
    "        B, T, _ = x.shape\n",
    "        mask = self.make_causal_mask(T).to(x.device)  # [T, T]\n",
    "        \n",
    "        for layer in self.dec_layers:\n",
    "            x = layer(x, enc_out, tgt_mask=mask)\n",
    "        \n",
    "        logits = self.output_proj(x)  # [B, T, vocab_size]\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "7e4e1be1-61ff-4848-928f-51eaa46b8fee",
    "_uuid": "18c57904-45e4-4d5d-bb6e-b6e411367de1",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:09:33.142586Z",
     "iopub.status.busy": "2025-08-13T15:09:33.142381Z",
     "iopub.status.idle": "2025-08-13T15:09:33.310131Z",
     "shell.execute_reply": "2025-08-13T15:09:33.309438Z",
     "shell.execute_reply.started": "2025-08-13T15:09:33.14257Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vocab_size = tokenizer.vocab_size\n",
    "embed_dim = 512\n",
    "ff_dim = 512\n",
    "num_heads = 8\n",
    "max_len = 102\n",
    "num_layers = 4\n",
    "\n",
    "decoder = CaptionDecoder(vocab_size, embed_dim, ff_dim, num_heads, max_len, num_layers)\n",
    "\n",
    "# Dummy inputs\n",
    "sample_tokens = x  # [B, T]\n",
    "img_features = output            # [B, N, D]\n",
    "\n",
    "output_logits = decoder(sample_tokens, img_features)\n",
    "print(output_logits.shape)  # [B, T, vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9ab3525a-b4f7-4cc0-b462-256aee089061",
    "_uuid": "98327b87-9d2a-42de-9ec6-1faf61146a55",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:09:33.314848Z",
     "iopub.status.busy": "2025-08-13T15:09:33.314618Z",
     "iopub.status.idle": "2025-08-13T15:09:33.323644Z",
     "shell.execute_reply": "2025-08-13T15:09:33.322958Z",
     "shell.execute_reply.started": "2025-08-13T15:09:33.31483Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "class ImageCaptioningModel(nn.Module):\n",
    "    def __init__(self, cnn_encoder, transformer_encoder, decoder, tokenizer):\n",
    "        super().__init__()\n",
    "        self.cnn_encoder = cnn_encoder\n",
    "        self.transformer_encoder = transformer_encoder\n",
    "        self.decoder = decoder\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def forward(self, images, captions):\n",
    "        img_features = self.cnn_encoder(images)\n",
    "        encoded_img = self.transformer_encoder(img_features)\n",
    "        logits = self.decoder(captions, encoded_img)\n",
    "        return logits\n",
    "\n",
    "    def generate(self, image, max_length=100, beam_width=3, device='cuda', length_penalty=0.7):\n",
    "        \"\"\"\n",
    "        Beam search decoding for image captioning.\n",
    "        \"\"\"\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            # Encode image\n",
    "            image = image.unsqueeze(0).to(device)  # [1, C, H, W]\n",
    "            img_features = self.cnn_encoder(image)\n",
    "            encoded_img = self.transformer_encoder(img_features)\n",
    "\n",
    "            # Beam: list of (sequence, score)\n",
    "            beam = [([self.tokenizer.sos_id], 0.0)]\n",
    "\n",
    "            for _ in range(max_length):\n",
    "                candidates = []\n",
    "                for seq, score in beam:\n",
    "                    if seq[-1] == self.tokenizer.eos_id:\n",
    "                        # Already ended, keep as is\n",
    "                        candidates.append((seq, score))\n",
    "                        continue\n",
    "\n",
    "                    # Predict next token\n",
    "                    input_ids = torch.tensor(seq).unsqueeze(0).to(device)  # [1, len]\n",
    "                    logits = self.decoder(input_ids, encoded_img)  # [1, len, vocab_size]\n",
    "                    probs = torch.softmax(logits[0, -1, :], dim=-1)  # last token probs\n",
    "\n",
    "                    # Get top-k next tokens\n",
    "                    topk_probs, topk_ids = probs.topk(beam_width)\n",
    "\n",
    "                    for prob, idx in zip(topk_probs, topk_ids):\n",
    "                        new_seq = seq + [idx.item()]\n",
    "                        new_score = score + math.log(prob.item() + 1e-12)  # sum log-probs\n",
    "                        candidates.append((new_seq, new_score))\n",
    "\n",
    "                # Keep best beam_width sequences (apply length penalty)\n",
    "                beam = sorted(\n",
    "                    candidates,\n",
    "                    key=lambda x: x[1] / ((len(x[0]) ** length_penalty) if length_penalty > 0 else 1),\n",
    "                    reverse=True\n",
    "                )[:beam_width]\n",
    "\n",
    "                # If all beams ended, stop early\n",
    "                if all(seq[-1] == self.tokenizer.eos_id for seq, _ in beam):\n",
    "                    break\n",
    "\n",
    "            # Return best sequence (highest score)\n",
    "            best_seq = beam[0][0]\n",
    "            return self.tokenizer.decode(best_seq, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f7b34070-dd51-43e4-982c-7913ce13dd03",
    "_uuid": "59087612-c84a-4d8a-a37b-73a59bd9d30f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:09:33.3246Z",
     "iopub.status.busy": "2025-08-13T15:09:33.324346Z",
     "iopub.status.idle": "2025-08-13T15:09:34.476367Z",
     "shell.execute_reply": "2025-08-13T15:09:34.475565Z",
     "shell.execute_reply.started": "2025-08-13T15:09:33.324577Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --- Model Hyperparameters ---\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "embed_dim = 512\n",
    "ff_dim = 512\n",
    "num_heads = 8\n",
    "num_decoder_layers = 4 # Keeping the decoder 4 layers deep\n",
    "vocab_size = tokenizer.vocab_size\n",
    "max_len = 102\n",
    "\n",
    "cnn_encoder = ImageEncoder(embed_dim=embed_dim)\n",
    "\n",
    "# 2. Transformer Encoder \n",
    "transformer_encoder = TransformerEncoderBlock(\n",
    "    embed_dim=embed_dim, \n",
    "    num_heads=num_heads, \n",
    "    ff_dim=ff_dim\n",
    ")\n",
    "\n",
    "# 3. Transformer Decoder \n",
    "decoder = CaptionDecoder(\n",
    "    vocab_size=vocab_size,\n",
    "    embed_dim=embed_dim,\n",
    "    ff_dim=ff_dim,\n",
    "    num_heads=num_heads,\n",
    "    max_len=max_len,\n",
    "    num_layers=num_decoder_layers\n",
    ")\n",
    "\n",
    "# 4. The full Image Captioning Model\n",
    "model = ImageCaptioningModel(\n",
    "    cnn_encoder=cnn_encoder,\n",
    "    transformer_encoder=transformer_encoder,\n",
    "    decoder=decoder,\n",
    "    tokenizer=tokenizer\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2d3c2399-d08f-4d68-9929-402b3dbd439e",
    "_uuid": "56d7ad70-b29c-4ca8-8553-f46127c684fc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:09:34.477556Z",
     "iopub.status.busy": "2025-08-13T15:09:34.477284Z",
     "iopub.status.idle": "2025-08-13T15:09:36.043513Z",
     "shell.execute_reply": "2025-08-13T15:09:36.042777Z",
     "shell.execute_reply.started": "2025-08-13T15:09:34.477531Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device='cuda'\n",
    "model = ImageCaptioningModel(cnn_encoder,transformer_encoder, decoder, tokenizer).to(device)\n",
    "\n",
    "# Assume `img_tensor` is [3, H, W] and preprocessed\n",
    "caption = model.generate(img_batch[0], max_length=40)\n",
    "print(\"Generated Caption:\", caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4711913d-7eb0-46a7-94a3-44048ae77485",
    "_uuid": "73eabfde-44a4-4eef-87e4-c1f9b80365ce",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:09:36.044525Z",
     "iopub.status.busy": "2025-08-13T15:09:36.044285Z",
     "iopub.status.idle": "2025-08-13T15:09:36.048757Z",
     "shell.execute_reply": "2025-08-13T15:09:36.047864Z",
     "shell.execute_reply.started": "2025-08-13T15:09:36.044509Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def caption_loss_fn(logits, targets, pad_token_id):\n",
    "    \"\"\"\n",
    "    logits: [B, T, vocab_size]\n",
    "    targets: [B, T] (next tokens)\n",
    "    \"\"\"\n",
    "    logits = logits.view(-1, logits.size(-1))   # [(B*T), vocab_size]\n",
    "    targets = targets.reshape(-1)                # [(B*T)]\n",
    "    \n",
    "    loss = F.cross_entropy(logits, targets, ignore_index=pad_token_id,label_smoothing=0.1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "129f1958-115c-4b47-9512-19368faaffac",
    "_uuid": "191ff540-5758-49e7-8572-08ac7ce75157",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:09:36.049593Z",
     "iopub.status.busy": "2025-08-13T15:09:36.049407Z",
     "iopub.status.idle": "2025-08-13T15:09:36.078129Z",
     "shell.execute_reply": "2025-08-13T15:09:36.077292Z",
     "shell.execute_reply.started": "2025-08-13T15:09:36.049578Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_one_epoch(model, dataloader, optimizer, pad_token_id, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for images, captions in tqdm(dataloader):\n",
    "        images, captions = images.to(device), captions.to(device)\n",
    "\n",
    "        # Inputs: captions[:-1], Targets: captions[1:]\n",
    "        inputs = captions[:, :-1]\n",
    "        targets = captions[:, 1:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(images, inputs)\n",
    "        loss = caption_loss_fn(logits, targets, pad_token_id)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "caf2f427-05e3-4864-a979-fbb4d16f6ef3",
    "_uuid": "ded7b738-ae81-458f-b5f7-17e0922ecbd7",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:09:36.079442Z",
     "iopub.status.busy": "2025-08-13T15:09:36.078911Z",
     "iopub.status.idle": "2025-08-13T15:09:36.098364Z",
     "shell.execute_reply": "2025-08-13T15:09:36.097349Z",
     "shell.execute_reply.started": "2025-08-13T15:09:36.07942Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def eval(model, dataloader, pad_token_id, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, captions in tqdm(dataloader):\n",
    "            images, captions = images.to(device), captions.to(device)\n",
    "    \n",
    "            # Inputs: captions[:-1], Targets: captions[1:]\n",
    "            inputs = captions[:, :-1]\n",
    "            targets = captions[:, 1:]\n",
    "    \n",
    "            logits = model(images, inputs)\n",
    "            loss = caption_loss_fn(logits, targets, pad_token_id)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "49b4f83b-e12c-4e04-a74f-e7f443d44fbc",
    "_uuid": "bcebf91a-18d5-42a4-b7be-a7c4d9841d58",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T15:09:36.099446Z",
     "iopub.status.busy": "2025-08-13T15:09:36.099185Z",
     "iopub.status.idle": "2025-08-13T18:27:05.993817Z",
     "shell.execute_reply": "2025-08-13T18:27:05.992827Z",
     "shell.execute_reply.started": "2025-08-13T15:09:36.099428Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "model = ImageCaptioningModel(cnn_encoder,transformer_encoder, decoder, tokenizer).to(device)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_model = copy.deepcopy(model.state_dict())\n",
    "# In your model setup cell (e.g., Cell 44)\n",
    "\n",
    "# 1. Separate parameters\n",
    "cnn_params = list(model.cnn_encoder.parameters())\n",
    "transformer_params = list(model.transformer_encoder.parameters()) + list(model.decoder.parameters())\n",
    "\n",
    "# Identify the last block of the CNN to fine-tune\n",
    "finetune_layers = model.cnn_encoder.backbone[-2:] # Example: unfreeze last 2 blocks\n",
    "finetune_params = list(finetune_layers.parameters())\n",
    "for param in model.cnn_encoder.backbone[-2:].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Freeze everything else in the CNN\n",
    "for param in model.cnn_encoder.backbone[:-2].parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. Setup optimizer with different learning rates\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': transformer_params, 'lr': 1e-4},\n",
    "    {'params': finetune_params, 'lr': 1e-5}\n",
    "])\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2, verbose=True)\n",
    "\n",
    "# Train for 60 epochs\n",
    "for epoch in range(50):\n",
    "    loss = train_one_epoch(model, train_loader, optimizer, tokenizer.pad_id, device)\n",
    "    val_loss = eval(model, val_loader, tokenizer.pad_id, device)\n",
    "    scheduler.step(val_loss)\n",
    "    if best_val_loss>val_loss:\n",
    "        print(\"Saving best model...\")\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}, eval_loss: {val_loss:.4f}\")\n",
    "\n",
    "print(\"loading the best model\")\n",
    "model.load_state_dict(best_model)  \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "979ac802-2f70-4104-9779-d54b73aee949",
    "_uuid": "5ec6959c-13f5-4ffc-b498-3a745e123138",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ecde9c1c-d0b1-42b2-817b-2417bd75c7a2",
    "_uuid": "da7165c7-1e57-4596-bb58-b656d30f16b2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T18:29:08.586942Z",
     "iopub.status.busy": "2025-08-13T18:29:08.585964Z",
     "iopub.status.idle": "2025-08-13T18:29:08.838959Z",
     "shell.execute_reply": "2025-08-13T18:29:08.838092Z",
     "shell.execute_reply.started": "2025-08-13T18:29:08.586915Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"X-ray_transformer_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3110120e-da41-49db-a72e-2cab41efc916",
    "_uuid": "e5f855c2-2b00-473d-bedf-bbc36f8ab77a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T18:31:08.461978Z",
     "iopub.status.busy": "2025-08-13T18:31:08.461697Z",
     "iopub.status.idle": "2025-08-13T18:31:08.776164Z",
     "shell.execute_reply": "2025-08-13T18:31:08.77534Z",
     "shell.execute_reply.started": "2025-08-13T18:31:08.461955Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = ImageCaptioningModel(cnn_encoder,transformer_encoder, decoder, tokenizer).to(device)\n",
    "model.load_state_dict(torch.load(\"X-ray_transformer_model.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0e9ff66e-0ea1-43b3-a40a-7671114c2215",
    "_uuid": "8364a52c-6d72-4f19-b65b-21606ca1371b",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f0c258df-50c2-437e-a7b5-b007c5890095",
    "_uuid": "0b2776f7-adf4-4c52-b163-3ae010944a6e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T18:31:46.012583Z",
     "iopub.status.busy": "2025-08-13T18:31:46.011858Z",
     "iopub.status.idle": "2025-08-13T18:31:56.434973Z",
     "shell.execute_reply": "2025-08-13T18:31:56.433946Z",
     "shell.execute_reply.started": "2025-08-13T18:31:46.012558Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install rouge_score\n",
    "!pip install bert_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "80f4ec99-660b-4ab2-a80b-e5dc58bd60b8",
    "_uuid": "93c0a45b-8537-4dba-8d48-794f9b7c9d77",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T18:32:27.938371Z",
     "iopub.status.busy": "2025-08-13T18:32:27.937865Z",
     "iopub.status.idle": "2025-08-13T18:32:28.212464Z",
     "shell.execute_reply": "2025-08-13T18:32:28.21171Z",
     "shell.execute_reply.started": "2025-08-13T18:32:27.938345Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1913190a-3652-4262-8109-a5559ec46393",
    "_uuid": "764f8e3b-425a-444f-bfeb-ed1f7fb6183a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T18:32:36.254758Z",
     "iopub.status.busy": "2025-08-13T18:32:36.254245Z",
     "iopub.status.idle": "2025-08-13T18:32:36.265214Z",
     "shell.execute_reply": "2025-08-13T18:32:36.264594Z",
     "shell.execute_reply.started": "2025-08-13T18:32:36.254734Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_scorer\n",
    "\n",
    "def evaluate_model(model, dataloader, tokenizer, device):\n",
    "    \"\"\"\n",
    "    Generates predictions and computes BLEU, ROUGE, METEOR, and BERTScore.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    references = []\n",
    "    hypotheses = []\n",
    "\n",
    "    # 1. Generate Predictions\n",
    "    print(\"Generating predictions on the test set...\")\n",
    "    with torch.no_grad():\n",
    "        for images, captions_seq in tqdm(dataloader):\n",
    "            # Move images to the correct device for model.generate\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Generate a caption for each image in the batch\n",
    "            for i in range(images.size(0)):\n",
    "                image = images[i]\n",
    "                generated_caption = model.generate(image, max_length=100, device=device)\n",
    "                hypotheses.append(generated_caption)\n",
    "\n",
    "            # Decode the ground truth captions\n",
    "            # The caption sequences are on the CPU by default from the dataloader\n",
    "            for seq in captions_seq:\n",
    "                ref_caption = tokenizer.decode(seq.tolist(), skip_special_tokens=True)\n",
    "                references.append(ref_caption)\n",
    "\n",
    "    print(f\"\\nGenerated {len(hypotheses)} hypotheses.\")\n",
    "    print(\"Example Hypothesis:\", hypotheses[0])\n",
    "    print(\"Example Reference: \", references[0])\n",
    "\n",
    "    # 2. Calculate Metrics\n",
    "    \n",
    "    # --- BLEU Score ---\n",
    "    print(\"\\nCalculating BLEU scores...\")\n",
    "    bleu_scores = {'bleu_1': 0, 'bleu_2': 0, 'bleu_3': 0, 'bleu_4': 0}\n",
    "    for ref, hyp in zip(references, hypotheses):\n",
    "        ref_tokens = [nltk.word_tokenize(ref)] # NLTK's sentence_bleu expects a list of reference translations\n",
    "        hyp_tokens = nltk.word_tokenize(hyp)\n",
    "        \n",
    "        bleu_scores['bleu_1'] += sentence_bleu(ref_tokens, hyp_tokens, weights=(1, 0, 0, 0))\n",
    "        bleu_scores['bleu_2'] += sentence_bleu(ref_tokens, hyp_tokens, weights=(0, 1, 0, 0))\n",
    "        bleu_scores['bleu_3'] += sentence_bleu(ref_tokens, hyp_tokens, weights=(0, 0, 1, 0))\n",
    "        bleu_scores['bleu_4'] += sentence_bleu(ref_tokens, hyp_tokens, weights=(0, 0, 0, 1))\n",
    "        \n",
    "    for k in bleu_scores:\n",
    "        bleu_scores[k] /= len(hypotheses)\n",
    "\n",
    "    # --- METEOR Score ---\n",
    "    print(\"Calculating METEOR scores...\")\n",
    "    meteor_total = 0\n",
    "    for ref, hyp in zip(references, hypotheses):\n",
    "        ref_tokens = nltk.word_tokenize(ref)\n",
    "        hyp_tokens = nltk.word_tokenize(hyp)\n",
    "        meteor_total += meteor_score([ref_tokens], hyp_tokens)\n",
    "    meteor_avg = meteor_total / len(hypotheses)\n",
    "    \n",
    "    # --- ROUGE Score ---\n",
    "    print(\"Calculating ROUGE scores...\")\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "    rouge_scores = {'rouge1': 0, 'rouge2': 0, 'rougeL': 0}\n",
    "    for ref, hyp in zip(references, hypotheses):\n",
    "        scores = scorer.score(ref, hyp)\n",
    "        rouge_scores['rouge1'] += scores['rouge1'].fmeasure\n",
    "        rouge_scores['rouge2'] += scores['rouge2'].fmeasure\n",
    "        rouge_scores['rougeL'] += scores['rougeL'].fmeasure\n",
    "        \n",
    "    for k in rouge_scores:\n",
    "        rouge_scores[k] /= len(hypotheses)\n",
    "\n",
    "    # --- BERTScore ---\n",
    "    # This is computationally intensive, will use GPU if available.\n",
    "    print(\"Calculating BERTScore\")\n",
    "    P, R, F1 = bert_scorer(hypotheses, references, lang=\"en\", model_type='distilbert-base-uncased', device=device, verbose=True)\n",
    "    bertscore_avg = F1.mean().item()\n",
    "\n",
    "    all_metrics = {\n",
    "        **bleu_scores,\n",
    "        'meteor': meteor_avg,\n",
    "        **rouge_scores,\n",
    "        'bert_score': bertscore_avg\n",
    "    }\n",
    "    \n",
    "    return all_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a46cfdb2-504f-48fe-9250-036d00b50df1",
    "_uuid": "18a2544f-0e62-4dea-bb48-bda7c5a61e81",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T18:32:47.492825Z",
     "iopub.status.busy": "2025-08-13T18:32:47.49216Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "# Run the evaluation\n",
    "test_metrics = evaluate_model(model, test_loader, tokenizer, device)\n",
    "\n",
    "# Print the final results in a clean format\n",
    "print(\"\\n--- Test Set Evaluation Metrics ---\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"{metric.upper():<12}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e5559ce8-475b-409f-b230-43c20999c0ab",
    "_uuid": "04eed768-d60b-4ae1-880a-686bc3732461",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T18:45:18.507098Z",
     "iopub.status.busy": "2025-08-13T18:45:18.506406Z",
     "iopub.status.idle": "2025-08-13T18:45:18.513366Z",
     "shell.execute_reply": "2025-08-13T18:45:18.512599Z",
     "shell.execute_reply.started": "2025-08-13T18:45:18.507073Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import textwrap\n",
    "\n",
    "def visualize_result(img_path, true_report, generated_report, title=\"Model Prediction\"):\n",
    "\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    wrapped_true = textwrap.fill(f\"Ground Truth: {true_report}\", width=100)\n",
    "    wrapped_gen = textwrap.fill(f\"Generated: {generated_report}\", width=100)\n",
    "    \n",
    "    plt.title(title, fontsize=14, pad=20)\n",
    "    plt.figtext(0.5, 0.01, f\"{wrapped_true}\\n\\n{wrapped_gen}\", \n",
    "                ha=\"center\", va=\"bottom\", fontsize=12, wrap=True, bbox={\"facecolor\":\"white\", \"alpha\":0.7, \"pad\":5})\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "64992e5e-c220-4b6f-8640-c08e9bc6e169",
    "_uuid": "9ef2d8cd-3295-433f-8ee6-e812741c6ad5",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T18:45:22.211457Z",
     "iopub.status.busy": "2025-08-13T18:45:22.210861Z",
     "iopub.status.idle": "2025-08-13T18:45:22.21753Z",
     "shell.execute_reply": "2025-08-13T18:45:22.216894Z",
     "shell.execute_reply.started": "2025-08-13T18:45:22.211433Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "def show_random_test_examples(model, test_df, tokenizer, image_transforms, device, num_examples=3):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    random_indices = random.sample(range(len(test_df)), num_examples)\n",
    "    \n",
    "    for i, idx in enumerate(random_indices):\n",
    "        sample_row = test_df.iloc[idx]\n",
    "        img_path = sample_row['path']\n",
    "        true_report = sample_row['report']\n",
    "        \n",
    "        image_pil = Image.open(img_path).convert(\"RGB\")\n",
    "        image_tensor = image_transforms(image_pil).unsqueeze(0).to(device)\n",
    "        \n",
    "        print(f\"--- Example {i+1}/{num_examples} ---\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            generated_report = model.generate(image_tensor.squeeze(0), max_length=100, device=device)\n",
    "        visualize_result(img_path, true_report, generated_report, title=f\"Test Example {i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "08b8020d-d62f-4ff1-b9b1-773175a8886f",
    "_uuid": "7e934dd0-6da9-4726-b696-3e1e3bcf4b10",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-13T18:41:42.066591Z",
     "iopub.status.busy": "2025-08-13T18:41:42.066264Z",
     "iopub.status.idle": "2025-08-13T18:42:01.868285Z",
     "shell.execute_reply": "2025-08-13T18:42:01.867252Z",
     "shell.execute_reply.started": "2025-08-13T18:41:42.066568Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "# Call the function to show 5 random examples\n",
    "show_random_test_examples(model, test_df, tokenizer, image_transforms, device, num_examples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "19e7f3ba-d069-4ffa-9f7c-a766d963c8d1",
    "_uuid": "d0e09779-2032-4984-ad7b-c1eea6e2257a",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 516716,
     "sourceId": 951996,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
